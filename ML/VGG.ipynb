{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8f5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/applications/vgg/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b674be8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe5bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert\n",
    "import random\n",
    "import multiprocessing\n",
    "from tensorflow.python.saved_model import signature_constants, tag_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "import subprocess as sp\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e7a80",
   "metadata": {},
   "source": [
    "# Load VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae80f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "\n",
    "    model = tf.keras.applications.VGG19(\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        classifier_activation=None,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ca71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a48ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Input Shape{model.input_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0204c710",
   "metadata": {},
   "source": [
    "# Test base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362017d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_path = 'assets/test_image.jpg'\n",
    "#There is an interpolation method to match the source size with the target size\n",
    "#image loaded in PIL (Python Imaging Library)\n",
    "img = image.load_img(img_path, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f25398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_as_array = image.img_to_array(img)\n",
    "#image_as_array = image_as_array.astype(np.int8)\n",
    "image_as_array = image_as_array.reshape(((1, image_as_array.shape[0], image_as_array.shape[1], image_as_array.shape[2])))\n",
    "test_image = tf.keras.applications.vgg19.preprocess_input(image_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7138b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float32'>\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[-74.68     , -22.779    ,  29.060997 ],\n",
       "         [-74.68     , -19.779    ,  31.060997 ],\n",
       "         [-72.68     , -20.779    ,  31.060997 ],\n",
       "         ...,\n",
       "         [-81.68     , -30.779    ,  21.060997 ],\n",
       "         [-83.68     , -31.779    ,  20.060997 ],\n",
       "         [-86.68     , -35.779    ,  14.060997 ]],\n",
       "\n",
       "        [[-75.68     , -16.779    ,  36.060997 ],\n",
       "         [-75.68     , -16.779    ,  36.060997 ],\n",
       "         [-72.68     , -13.778999 ,  39.060997 ],\n",
       "         ...,\n",
       "         [-81.68     , -26.779    ,  26.060997 ],\n",
       "         [-79.68     , -29.779    ,  25.060997 ],\n",
       "         [-82.68     , -32.779    ,  22.060997 ]],\n",
       "\n",
       "        [[-75.68     , -16.779    ,  36.060997 ],\n",
       "         [-74.68     , -15.778999 ,  37.060997 ],\n",
       "         [-73.68     , -13.778999 ,  41.060997 ],\n",
       "         ...,\n",
       "         [-80.68     , -26.779    ,  28.060997 ],\n",
       "         [-79.68     , -29.779    ,  25.060997 ],\n",
       "         [-82.68     , -32.779    ,  22.060997 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-86.68     , -41.779    ,  -5.939003 ],\n",
       "         [-87.68     , -42.779    ,  -6.939003 ],\n",
       "         [-86.68     , -41.779    ,  -5.939003 ],\n",
       "         ...,\n",
       "         [ 11.32     , -27.779    , -66.939    ],\n",
       "         [  1.3199997, -33.779    , -70.939    ],\n",
       "         [  3.3199997, -31.779    , -66.939    ]],\n",
       "\n",
       "        [[-86.68     , -43.779    ,  -6.939003 ],\n",
       "         [-85.68     , -42.779    ,  -5.939003 ],\n",
       "         [-83.68     , -38.779    ,  -2.939003 ],\n",
       "         ...,\n",
       "         [  8.32     , -27.779    , -65.939    ],\n",
       "         [  6.3199997, -28.779    , -63.939003 ],\n",
       "         [  4.3199997, -31.779    , -63.939003 ]],\n",
       "\n",
       "        [[-87.68     , -45.779    , -10.939003 ],\n",
       "         [-86.68     , -43.779    ,  -8.939003 ],\n",
       "         [-86.68     , -43.779    ,  -6.939003 ],\n",
       "         ...,\n",
       "         [ 12.32     , -24.779    , -60.939003 ],\n",
       "         [  9.32     , -23.779    , -59.939003 ],\n",
       "         [  4.3199997, -29.779    , -62.939003 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(image_as_array[0][0][0][0]))\n",
    "print(test_image.shape)\n",
    "image_as_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97685adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(pred)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d4bc5",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7c584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = 'saved_model/base_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(base_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7084b",
   "metadata": {},
   "source": [
    "# Convert model to TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7b9cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (8, 0, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (8, 0, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 10:35:10.770147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:10.814350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:10.814774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:10.815838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:10.816287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:10.816768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:12.635451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:12.636483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:12.637151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:12.637669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13712 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-05-17 10:35:17.502360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:17.502674: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-05-17 10:35:17.502834: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-05-17 10:35:17.503728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:17.504228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:17.504652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:17.505134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:17.505563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:17.505983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13712 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-05-17 10:35:17.514475: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 185 nodes (143), 260 edges (218), time = 4.066ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.095ms.\n",
      "\n",
      "2022-05-17 10:35:25.170640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:25.170984: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-05-17 10:35:25.171160: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-05-17 10:35:25.172204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:25.172732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:25.173080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:25.173522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:25.173873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-17 10:35:25.174167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13712 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_932/770320961.py\", line 14, in optimize_model\n",
      "    converter.convert()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 1171, in convert\n",
      "    self._converted_graph_def = self._run_conversion(grappler_meta_graph_def)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 1104, in _run_conversion\n",
      "    return tf_optimizer.OptimizeGraph(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/grappler/tf_optimizer.py\", line 55, in OptimizeGraph\n",
      "    out_graph = tf_opt.TF_OptimizeGraph(cluster.tf_cluster,\n",
      "MemoryError: std::bad_alloc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def optimize_model(precision_mode='FP32'):\n",
    "    converter = trt_convert.TrtGraphConverterV2(input_saved_model_dir=base_model_path,\n",
    "                                        conversion_params = tf.experimental.tensorrt.ConversionParams(\n",
    "                                            precision_mode=precision_mode,\n",
    "                                        ), max_workspace_size_bytes=1 << 28\n",
    "                                       )\n",
    "\n",
    "\n",
    "    def my_input_fn():\n",
    "        # Input for a single inference call, for a network that has two input tensors:\n",
    "        yield (np.asanyarray([test_image]),)\n",
    "\n",
    "\n",
    "    converter.convert()\n",
    "    converter.build(my_input_fn)\n",
    "    model_path = './optimized' + '_' + precision_mode\n",
    "    converter.save(model_path)\n",
    "\n",
    "p = multiprocessing.Process(target=optimize_model)\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "\n",
    "#p = multiprocessing.Process(target=optimize_model('FP16'))\n",
    "#p.start()\n",
    "#p.join()\n",
    "#optimize_model('FP16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b9524",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_32 = './optimized' + \"_\" + 'FP32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f0a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_gpu_memory():\n",
    "  _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "\n",
    "  ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "  COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "  memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "  memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "  return memory_free_values\n",
    "\n",
    "def get_func_from_saved_model(saved_model_dir):\n",
    "  saved_model_loaded = tf.saved_model.load(\n",
    "      saved_model_dir, tags=[tag_constants.SERVING])\n",
    "  graph_func = saved_model_loaded.signatures[\n",
    "      signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "  graph_func = convert_to_constants.convert_variables_to_constants_v2(graph_func)\n",
    "  return graph_func\n",
    "\n",
    "def evaluate_model(saved_model_dir):\n",
    "    print(\"Model: \" + saved_model_dir)\n",
    "    mem_before = get_gpu_memory()[0]\n",
    "    print(\"Available GPU Memory before loading: \", mem_before)\n",
    "\n",
    "    model_func = get_func_from_saved_model(saved_model_dir)\n",
    "    mem_after = get_gpu_memory()[0]\n",
    "    print(\"Available GPU Memory after loading: \", mem_after)\n",
    "\n",
    "    print(\"GPU Memory Usage: \" + str(mem_before - mem_after) + \" MiB\")\n",
    "    model_func(test_image)\n",
    "    print('\\nTest accuracy:', float(success) / num_of_iteration)\n",
    "\n",
    "p = multiprocessing.Process(target=evaluate_model(model_path_32))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc2b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
