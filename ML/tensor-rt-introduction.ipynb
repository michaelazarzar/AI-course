{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e406a6b",
   "metadata": {},
   "source": [
    "# Introduction To TensorRT\n",
    "\n",
    "## What is TensorRT?\n",
    "TensorRT is an optimization SDK created by Nvidia corp to enable optimal performance tailoring to Nvidia's different GPGPU (General Perpose GPU's) serieses.\n",
    "\n",
    "TensorRT is post training optimization, that means that after the selected architecture is trained, TensorRT receives the model description and weights and optimizes the model graph to perform the inference faster and with smaller footprint on specific target platform.\n",
    "<br><br><img src=\"images/tensorrt-overview.png\" height=\"30%\" width=\"30%\"/><br><br>\n",
    "\n",
    "TensorRT has SDK in C++ and Python.\n",
    "\n",
    "TensorRT accepts as an input model description and weights, and performs different optimizations to the model:<br>\n",
    "1. Reduce Mixed Precision - maximizes throughput by **quantizing** models to **FP16 & INT8(With Calibration)** while preserving accuracy<br>\n",
    "2. Layer and Tensor Fusion - optimizes use of GPU memory and bandwidth by fusing nodes in a kernel<br>\n",
    "3. Kernel Auto-Tuning - selects best data layers and algorithms based on the target GPU platform<br>\n",
    "4. Dynamic Tensor Memory - minimizes memory footprint and reuses memory for tensors efficiently<br>\n",
    "5. Multi-Stream Execution - uses a scalable design to process multiple input streams in parallel<br>\n",
    "6. Time Fusion - optimizes recurrent neural networks over time steps with dynamically generated kernels<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "TensorRT supports compilation to highly efficient execution of verity of different DNN functions, one can also specify parts of the graph that should not optimize (mostly done when a function is not supported by TensorRT conversion - in newer versions ignores on its on)\n",
    "<br><br><img src=\"images/tensorrt-graph-optimization.png\" height=\"60%\" width=\"60%\"/><br><br>\n",
    "\n",
    "> Note: The generated plan files are not portable across platforms or TensorRT versions, and are specific to the exact GPU model they were built on.\n",
    "<br><br>\n",
    "\n",
    "To describe the network to TensorRT we have few options:\n",
    "* Describe the network architecture explicitly and convert weights to descriptor with Python & C++ API\n",
    "* Integration with existing deep learning frameworks (TF-TRT[tensorflow], caffe)\n",
    "* Using TensorRT ONNX parser load ONNX descriptor (possibly generated from DL framework)\n",
    "<br><br><img src=\"images/tensorrt-onnx-parser.png\"/>\n",
    "\n",
    "\n",
    "In the following sessions we will work with TF-TRT, a tensorflow wrapper around TensorRT, the method of operation is the following:\n",
    "<br><br><img src=\"images/tensorrt-workflow.png\" height=\"60%\" width=\"60%\"/><br><br>\n",
    "\n",
    "> Note: its also possible to serialize the model and deserialize it in C++ tensorrt API or TensorRT Inference Server, thus allow not using tensorflow for inference at all.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3028072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "    # reshape dataset to have a single channel\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "train_images, train_labels, validation_images, validation_labels = load_dataset()\n",
    "\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(train_images[i], cmap=pyplot.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# show the figure\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed77d76",
   "metadata": {},
   "source": [
    "to_categorical - function that takes vector input with the size of number of classes where the selected class index is 1 and returns the number of class (index of 1 in the vector), we do this because the loss function of the model is CategoricalCrossEntropy which calculates loss between the most likely prediction (after softmax) to the ground truth (more efficient because in the back propegation only the ground truth 1 value get back propegated)\n",
    "<br><br>\n",
    "## Dataset Preprocessing\n",
    "Convert each pixel to float32 with normalized value from(0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7d44a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done converting to float32 normalized values\n"
     ]
    }
   ],
   "source": [
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "\n",
    "train_images, validation_images = prep_pixels(train_images, validation_images)\n",
    "print(\"Done converting to float32 normalized values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366ccc9",
   "metadata": {},
   "source": [
    "## Create and Train The Model\n",
    "As a rule of thumb MSE (mean squere error, L2 Loss) is more suitable as a loss function to regression problems and CrossEntropy is more relevant for classification problems\n",
    "Binary cross entropy is more suitable for binning the different classifications in the data, MSE is better for regression as it is more tolerrant for close values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb04943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:58:49.989961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.050485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.050919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.052535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.052970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.053410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.571725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.572241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.572683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:58:50.573029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 10:58:51.204497: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:58:51.427806: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2022-04-26 10:58:51.580259: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-26 10:58:52.888383: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - ETA: 1:19:23 - loss: 2.7605 - accuracy: 0.031 - ETA: 2:29 - loss: 2.5196 - accuracy: 0.0625  - ETA: 2:08 - loss: 2.3997 - accuracy: 0.15 - ETA: 1:45 - loss: 2.2026 - accuracy: 0.23 - ETA: 1:42 - loss: 2.1366 - accuracy: 0.27 - ETA: 1:41 - loss: 2.0214 - accuracy: 0.30 - ETA: 1:34 - loss: 1.8142 - accuracy: 0.37 - ETA: 1:29 - loss: 1.6256 - accuracy: 0.44 - ETA: 1:26 - loss: 1.4788 - accuracy: 0.50 - ETA: 1:06 - loss: 1.2870 - accuracy: 0.56 - ETA: 34s - loss: 1.0074 - accuracy: 0.6797 - ETA: 24s - loss: 0.8898 - accuracy: 0.712 - ETA: 20s - loss: 0.7727 - accuracy: 0.751 - ETA: 16s - loss: 0.7142 - accuracy: 0.776 - ETA: 14s - loss: 0.6748 - accuracy: 0.788 - ETA: 12s - loss: 0.6375 - accuracy: 0.800 - ETA: 12s - loss: 0.6144 - accuracy: 0.808 - ETA: 11s - loss: 0.5920 - accuracy: 0.817 - ETA: 10s - loss: 0.5619 - accuracy: 0.825 - ETA: 9s - loss: 0.5395 - accuracy: 0.832 - ETA: 9s - loss: 0.5218 - accuracy: 0.83 - ETA: 8s - loss: 0.5072 - accuracy: 0.84 - ETA: 8s - loss: 0.4864 - accuracy: 0.84 - ETA: 8s - loss: 0.4682 - accuracy: 0.85 - ETA: 7s - loss: 0.4570 - accuracy: 0.85 - ETA: 7s - loss: 0.4434 - accuracy: 0.86 - ETA: 7s - loss: 0.4334 - accuracy: 0.86 - ETA: 7s - loss: 0.4215 - accuracy: 0.86 - ETA: 6s - loss: 0.4119 - accuracy: 0.87 - ETA: 6s - loss: 0.4053 - accuracy: 0.87 - ETA: 6s - loss: 0.3994 - accuracy: 0.87 - ETA: 6s - loss: 0.3939 - accuracy: 0.87 - ETA: 6s - loss: 0.3884 - accuracy: 0.87 - ETA: 6s - loss: 0.3803 - accuracy: 0.88 - ETA: 5s - loss: 0.3712 - accuracy: 0.88 - ETA: 5s - loss: 0.3620 - accuracy: 0.88 - ETA: 5s - loss: 0.3574 - accuracy: 0.88 - ETA: 5s - loss: 0.3519 - accuracy: 0.88 - ETA: 5s - loss: 0.3461 - accuracy: 0.89 - ETA: 5s - loss: 0.3416 - accuracy: 0.89 - ETA: 5s - loss: 0.3385 - accuracy: 0.89 - ETA: 4s - loss: 0.3338 - accuracy: 0.89 - ETA: 4s - loss: 0.3300 - accuracy: 0.89 - ETA: 4s - loss: 0.3255 - accuracy: 0.89 - ETA: 4s - loss: 0.3224 - accuracy: 0.89 - ETA: 4s - loss: 0.3176 - accuracy: 0.90 - ETA: 4s - loss: 0.3156 - accuracy: 0.90 - ETA: 4s - loss: 0.3128 - accuracy: 0.90 - ETA: 4s - loss: 0.3087 - accuracy: 0.90 - ETA: 4s - loss: 0.3045 - accuracy: 0.90 - ETA: 4s - loss: 0.3005 - accuracy: 0.90 - ETA: 4s - loss: 0.2971 - accuracy: 0.90 - ETA: 3s - loss: 0.2942 - accuracy: 0.90 - ETA: 3s - loss: 0.2905 - accuracy: 0.90 - ETA: 3s - loss: 0.2882 - accuracy: 0.90 - ETA: 3s - loss: 0.2852 - accuracy: 0.91 - ETA: 3s - loss: 0.2826 - accuracy: 0.91 - ETA: 3s - loss: 0.2804 - accuracy: 0.91 - ETA: 3s - loss: 0.2777 - accuracy: 0.91 - ETA: 3s - loss: 0.2743 - accuracy: 0.91 - ETA: 3s - loss: 0.2714 - accuracy: 0.91 - ETA: 3s - loss: 0.2682 - accuracy: 0.91 - ETA: 3s - loss: 0.2651 - accuracy: 0.91 - ETA: 3s - loss: 0.2631 - accuracy: 0.91 - ETA: 2s - loss: 0.2610 - accuracy: 0.91 - ETA: 2s - loss: 0.2590 - accuracy: 0.91 - ETA: 2s - loss: 0.2565 - accuracy: 0.92 - ETA: 2s - loss: 0.2536 - accuracy: 0.92 - ETA: 2s - loss: 0.2516 - accuracy: 0.92 - ETA: 2s - loss: 0.2496 - accuracy: 0.92 - ETA: 2s - loss: 0.2473 - accuracy: 0.92 - ETA: 2s - loss: 0.2463 - accuracy: 0.92 - ETA: 2s - loss: 0.2448 - accuracy: 0.92 - ETA: 2s - loss: 0.2432 - accuracy: 0.92 - ETA: 2s - loss: 0.2411 - accuracy: 0.92 - ETA: 2s - loss: 0.2396 - accuracy: 0.92 - ETA: 2s - loss: 0.2380 - accuracy: 0.92 - ETA: 2s - loss: 0.2370 - accuracy: 0.92 - ETA: 2s - loss: 0.2350 - accuracy: 0.92 - ETA: 1s - loss: 0.2328 - accuracy: 0.92 - ETA: 1s - loss: 0.2308 - accuracy: 0.92 - ETA: 1s - loss: 0.2291 - accuracy: 0.92 - ETA: 1s - loss: 0.2280 - accuracy: 0.92 - ETA: 1s - loss: 0.2266 - accuracy: 0.92 - ETA: 1s - loss: 0.2257 - accuracy: 0.93 - ETA: 1s - loss: 0.2244 - accuracy: 0.93 - ETA: 1s - loss: 0.2225 - accuracy: 0.93 - ETA: 1s - loss: 0.2211 - accuracy: 0.93 - ETA: 1s - loss: 0.2198 - accuracy: 0.93 - ETA: 1s - loss: 0.2179 - accuracy: 0.93 - ETA: 1s - loss: 0.2167 - accuracy: 0.93 - ETA: 1s - loss: 0.2154 - accuracy: 0.93 - ETA: 1s - loss: 0.2143 - accuracy: 0.93 - ETA: 1s - loss: 0.2128 - accuracy: 0.93 - ETA: 1s - loss: 0.2114 - accuracy: 0.93 - ETA: 0s - loss: 0.2101 - accuracy: 0.93 - ETA: 0s - loss: 0.2090 - accuracy: 0.93 - ETA: 0s - loss: 0.2079 - accuracy: 0.93 - ETA: 0s - loss: 0.2066 - accuracy: 0.93 - ETA: 0s - loss: 0.2055 - accuracy: 0.93 - ETA: 0s - loss: 0.2040 - accuracy: 0.93 - ETA: 0s - loss: 0.2028 - accuracy: 0.93 - ETA: 0s - loss: 0.2016 - accuracy: 0.93 - ETA: 0s - loss: 0.2004 - accuracy: 0.93 - ETA: 0s - loss: 0.1994 - accuracy: 0.93 - ETA: 0s - loss: 0.1983 - accuracy: 0.93 - ETA: 0s - loss: 0.1976 - accuracy: 0.93 - ETA: 0s - loss: 0.1967 - accuracy: 0.93 - ETA: 0s - loss: 0.1956 - accuracy: 0.93 - ETA: 0s - loss: 0.1947 - accuracy: 0.94 - ETA: 0s - loss: 0.1939 - accuracy: 0.94 - ETA: 0s - loss: 0.1931 - accuracy: 0.94 - ETA: 0s - loss: 0.1922 - accuracy: 0.94 - 8s 3ms/step - loss: 0.1921 - accuracy: 0.9408\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - ETA: 12s - loss: 0.0675 - accuracy: 0.968 - ETA: 4s - loss: 0.0661 - accuracy: 0.981 - ETA: 5s - loss: 0.0606 - accuracy: 0.98 - ETA: 5s - loss: 0.0552 - accuracy: 0.98 - ETA: 5s - loss: 0.0560 - accuracy: 0.98 - ETA: 4s - loss: 0.0571 - accuracy: 0.98 - ETA: 4s - loss: 0.0586 - accuracy: 0.98 - ETA: 4s - loss: 0.0586 - accuracy: 0.98 - ETA: 4s - loss: 0.0626 - accuracy: 0.98 - ETA: 4s - loss: 0.0661 - accuracy: 0.98 - ETA: 4s - loss: 0.0653 - accuracy: 0.98 - ETA: 4s - loss: 0.0669 - accuracy: 0.98 - ETA: 4s - loss: 0.0676 - accuracy: 0.98 - ETA: 4s - loss: 0.0659 - accuracy: 0.98 - ETA: 4s - loss: 0.0675 - accuracy: 0.98 - ETA: 4s - loss: 0.0675 - accuracy: 0.98 - ETA: 4s - loss: 0.0676 - accuracy: 0.98 - ETA: 4s - loss: 0.0667 - accuracy: 0.98 - ETA: 4s - loss: 0.0672 - accuracy: 0.98 - ETA: 4s - loss: 0.0669 - accuracy: 0.98 - ETA: 4s - loss: 0.0679 - accuracy: 0.98 - ETA: 4s - loss: 0.0687 - accuracy: 0.98 - ETA: 4s - loss: 0.0686 - accuracy: 0.98 - ETA: 4s - loss: 0.0688 - accuracy: 0.98 - ETA: 4s - loss: 0.0692 - accuracy: 0.98 - ETA: 4s - loss: 0.0689 - accuracy: 0.98 - ETA: 3s - loss: 0.0689 - accuracy: 0.98 - ETA: 3s - loss: 0.0686 - accuracy: 0.98 - ETA: 3s - loss: 0.0681 - accuracy: 0.98 - ETA: 4s - loss: 0.0676 - accuracy: 0.98 - ETA: 4s - loss: 0.0672 - accuracy: 0.98 - ETA: 4s - loss: 0.0673 - accuracy: 0.98 - ETA: 4s - loss: 0.0673 - accuracy: 0.98 - ETA: 4s - loss: 0.0678 - accuracy: 0.98 - ETA: 4s - loss: 0.0681 - accuracy: 0.98 - ETA: 3s - loss: 0.0678 - accuracy: 0.98 - ETA: 3s - loss: 0.0676 - accuracy: 0.98 - ETA: 3s - loss: 0.0673 - accuracy: 0.98 - ETA: 3s - loss: 0.0680 - accuracy: 0.98 - ETA: 3s - loss: 0.0683 - accuracy: 0.98 - ETA: 3s - loss: 0.0681 - accuracy: 0.98 - ETA: 3s - loss: 0.0678 - accuracy: 0.97 - ETA: 3s - loss: 0.0679 - accuracy: 0.97 - ETA: 3s - loss: 0.0685 - accuracy: 0.97 - ETA: 3s - loss: 0.0688 - accuracy: 0.97 - ETA: 3s - loss: 0.0690 - accuracy: 0.97 - ETA: 3s - loss: 0.0688 - accuracy: 0.97 - ETA: 3s - loss: 0.0687 - accuracy: 0.97 - ETA: 3s - loss: 0.0685 - accuracy: 0.97 - ETA: 3s - loss: 0.0678 - accuracy: 0.98 - ETA: 3s - loss: 0.0681 - accuracy: 0.97 - ETA: 2s - loss: 0.0688 - accuracy: 0.97 - ETA: 2s - loss: 0.0687 - accuracy: 0.97 - ETA: 2s - loss: 0.0690 - accuracy: 0.97 - ETA: 2s - loss: 0.0683 - accuracy: 0.97 - ETA: 2s - loss: 0.0682 - accuracy: 0.97 - ETA: 2s - loss: 0.0677 - accuracy: 0.97 - ETA: 2s - loss: 0.0677 - accuracy: 0.97 - ETA: 2s - loss: 0.0673 - accuracy: 0.97 - ETA: 2s - loss: 0.0672 - accuracy: 0.97 - ETA: 2s - loss: 0.0668 - accuracy: 0.97 - ETA: 2s - loss: 0.0666 - accuracy: 0.97 - ETA: 2s - loss: 0.0671 - accuracy: 0.97 - ETA: 2s - loss: 0.0667 - accuracy: 0.97 - ETA: 2s - loss: 0.0662 - accuracy: 0.98 - ETA: 2s - loss: 0.0663 - accuracy: 0.98 - ETA: 2s - loss: 0.0664 - accuracy: 0.98 - ETA: 2s - loss: 0.0668 - accuracy: 0.97 - ETA: 2s - loss: 0.0667 - accuracy: 0.97 - ETA: 1s - loss: 0.0668 - accuracy: 0.97 - ETA: 1s - loss: 0.0665 - accuracy: 0.97 - ETA: 1s - loss: 0.0661 - accuracy: 0.97 - ETA: 1s - loss: 0.0665 - accuracy: 0.97 - ETA: 1s - loss: 0.0667 - accuracy: 0.97 - ETA: 1s - loss: 0.0667 - accuracy: 0.97 - ETA: 1s - loss: 0.0669 - accuracy: 0.97 - ETA: 1s - loss: 0.0669 - accuracy: 0.97 - ETA: 1s - loss: 0.0672 - accuracy: 0.97 - ETA: 1s - loss: 0.0673 - accuracy: 0.97 - ETA: 1s - loss: 0.0674 - accuracy: 0.97 - ETA: 1s - loss: 0.0672 - accuracy: 0.97 - ETA: 1s - loss: 0.0671 - accuracy: 0.97 - ETA: 1s - loss: 0.0669 - accuracy: 0.97 - ETA: 1s - loss: 0.0670 - accuracy: 0.97 - ETA: 1s - loss: 0.0669 - accuracy: 0.97 - ETA: 1s - loss: 0.0666 - accuracy: 0.97 - ETA: 1s - loss: 0.0666 - accuracy: 0.97 - ETA: 1s - loss: 0.0664 - accuracy: 0.97 - ETA: 1s - loss: 0.0661 - accuracy: 0.97 - ETA: 0s - loss: 0.0658 - accuracy: 0.97 - ETA: 0s - loss: 0.0656 - accuracy: 0.97 - ETA: 0s - loss: 0.0653 - accuracy: 0.97 - ETA: 0s - loss: 0.0652 - accuracy: 0.97 - ETA: 0s - loss: 0.0652 - accuracy: 0.97 - ETA: 0s - loss: 0.0650 - accuracy: 0.98 - ETA: 0s - loss: 0.0651 - accuracy: 0.98 - ETA: 0s - loss: 0.0651 - accuracy: 0.98 - ETA: 0s - loss: 0.0650 - accuracy: 0.98 - ETA: 0s - loss: 0.0650 - accuracy: 0.98 - ETA: 0s - loss: 0.0651 - accuracy: 0.98 - ETA: 0s - loss: 0.0652 - accuracy: 0.97 - ETA: 0s - loss: 0.0652 - accuracy: 0.97 - ETA: 0s - loss: 0.0652 - accuracy: 0.97 - ETA: 0s - loss: 0.0653 - accuracy: 0.97 - ETA: 0s - loss: 0.0652 - accuracy: 0.97 - ETA: 0s - loss: 0.0651 - accuracy: 0.97 - ETA: 0s - loss: 0.0650 - accuracy: 0.97 - 5s 3ms/step - loss: 0.0650 - accuracy: 0.9799\n",
      "313/313 - 1s - loss: 0.0612 - accuracy: 0.9801\n",
      "\n",
      "Test accuracy: 0.9800999760627747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:59:06.605070: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "def create_model_and_train( ):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=2)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(validation_images, validation_labels, verbose=2)\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "    model.save('./saved_model')\n",
    "\n",
    "# We are running training in a sepperate process so we can close it and free resources when done training\n",
    "p = multiprocessing.Process(target=create_model_and_train)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2bffd",
   "metadata": {},
   "source": [
    "This network architecture differs from the one in the previous lesson, now we have a convolution layes and pool max layer.<br>\n",
    "\n",
    "### Convolution Layer - perform convolution with selected kernel size on the input data<br>\n",
    "<center><img src=\"images/convolutional.png\" height=\"60%\" width=\"60%\"/></center><br>\n",
    "\n",
    "### Max Pool - down sampling technique with different kernel sizes to control different resolutions<br>\n",
    "\n",
    "<center><img src=\"images/max-pool.png\" height=\"60%\" width=\"60%\"/><br></center>\n",
    "<br><br>\n",
    "> Note: in most of modern implemented optimizers (SGD, ADAM, etc..) there is another parameter used to help minimize the risk for local minimum with low learning rate, **momentum** is the inertia of the optimizer and it is calculated each iteration from the slope of the gardient<br><br>\n",
    "<center><img src=\"images/momentum.jpeg\" height=\"45%\" width=\"45%\"/><br></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8f74f",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "### Saved model directory structure\n",
    "Please perform the training of the model and save it, after saving it explain the structure of the folder (find answer in Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3a5fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 26 11:02:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   60C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73da6e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel protocol buffer\r\n",
      "* saved_model.pb or saved_model.pbtxt\r\n",
      "* Includes the graph definitions as MetaGraphDef protocol buffers.\r\n",
      "Assets\r\n",
      "* Subfolder called assets.\r\n",
      "* Contains auxiliary files such as vocabularies, etc.\r\n",
      "Extra assets\r\n",
      "* Subfolder where higher-level libraries and users can add their own assets that * * co-exist with the model, but are not loaded by the graph.\r\n",
      "* This subfolder is not managed by the SavedModel libraries.\r\n",
      "Variables\r\n",
      "* Subfolder called variables.\r\n",
      "* variables.data-?????-of-?????\r\n",
      "* variables.index\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "solution = 'U2F2ZWRNb2RlbCBwcm90b2NvbCBidWZmZXINCiogc2F2ZWRfbW9kZWwucGIgb3Igc2F2ZWRfbW9kZWwucGJ0eHQNCiogSW5jbHVkZXMgdGhlIGdyYXBoIGRlZmluaXRpb25zIGFzIE1ldGFHcmFwaERlZiBwcm90b2NvbCBidWZmZXJzLg0KQXNzZXRzDQoqIFN1YmZvbGRlciBjYWxsZWQgYXNzZXRzLg0KKiBDb250YWlucyBhdXhpbGlhcnkgZmlsZXMgc3VjaCBhcyB2b2NhYnVsYXJpZXMsIGV0Yy4NCkV4dHJhIGFzc2V0cw0KKiBTdWJmb2xkZXIgd2hlcmUgaGlnaGVyLWxldmVsIGxpYnJhcmllcyBhbmQgdXNlcnMgY2FuIGFkZCB0aGVpciBvd24gYXNzZXRzIHRoYXQgKiAqIGNvLWV4aXN0IHdpdGggdGhlIG1vZGVsLCBidXQgYXJlIG5vdCBsb2FkZWQgYnkgdGhlIGdyYXBoLg0KKiBUaGlzIHN1YmZvbGRlciBpcyBub3QgbWFuYWdlZCBieSB0aGUgU2F2ZWRNb2RlbCBsaWJyYXJpZXMuDQpWYXJpYWJsZXMNCiogU3ViZm9sZGVyIGNhbGxlZCB2YXJpYWJsZXMuDQoqIHZhcmlhYmxlcy5kYXRhLT8/Pz8/LW9mLT8/Pz8/DQoqIHZhcmlhYmxlcy5pbmRleA=='\n",
    "\n",
    "base64_bytes = solution.encode('ascii')\n",
    "message_bytes = base64.b64decode(base64_bytes)\n",
    "decoded_solution = message_bytes.decode('ascii')\n",
    "\n",
    "print(decoded_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62ccfa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU Memory before loading:  15109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:04:47.822392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:47.879180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:47.879759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:47.881205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:47.881721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:47.882215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:48.399942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:48.400551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:48.400980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:04:48.401425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU Memory after loading:  1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:04:49.284794: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-26 11:04:50.322829: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FPS:  23.48367168869515\n",
      "GPU Memory Usage: 14046 MiB\n",
      "\n",
      "Test accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "num_of_iteration = 200\n",
    "\n",
    "def get_gpu_memory():\n",
    "  _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "\n",
    "  ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "  COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "  memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "  memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "  return memory_free_values\n",
    "\n",
    "def evaluate_model( ):\n",
    "    mem_before = get_gpu_memory()[0]\n",
    "    print(\"Available GPU Memory before loading: \", mem_before)\n",
    "\n",
    "    model = tf.keras.models.load_model('./saved_model')\n",
    "    mem_after = get_gpu_memory()[0]\n",
    "    print(\"Available GPU Memory after loading: \", mem_after)\n",
    "\n",
    "    \n",
    "    start_time = time.time()\n",
    "    success = 0\n",
    "    for i in range(num_of_iteration):\n",
    "        digit = np.argmax(model.predict(np.asanyarray([validation_images[i]]),), axis=-1)\n",
    "        if digit[0] == np.argmax(validation_labels[i]):\n",
    "            success += 1\n",
    "            \n",
    "\n",
    "    print(\"Average FPS: \", num_of_iteration / (time.time() - start_time))\n",
    "    print(\"GPU Memory Usage: \" + str(mem_before - mem_after) + \" MiB\")\n",
    "    print('\\nTest accuracy:', float(success) / num_of_iteration)\n",
    "\n",
    "p = multiprocessing.Process(target=evaluate_model)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83c653",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Load the model and measure the inference throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84cdb3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def next_number():\n",
    "    a = 0\n",
    "    while True:\n",
    "        a += 1\n",
    "        yield a\n",
    "        \n",
    "gen = next_number()\n",
    "print(next(gen))\n",
    "print(next(gen))\n",
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96764e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (8, 0, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (8, 0, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:17:22.197123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.247013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.247384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.248414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.248772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.249109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.773014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.773407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.773729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:22.774038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:17:23.205753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.206550: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-26 11:17:23.207040: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-26 11:17:23.208034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.208670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.209260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.209869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.210447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.210952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:17:23.214088: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 38 nodes (28), 49 edges (39), time = 1.047ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.028ms.\n",
      "\n",
      "2022-04-26 11:17:23.267242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.267549: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-26 11:17:23.267898: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-26 11:17:23.268827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.269506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.270009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.270591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.271091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:17:23.271618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:17:23.296410: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:883] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/unconverted OP Report:\n",
      "\t- NoOp -> 5x\n",
      "\t- Placeholder -> 1x\n",
      "\t- Identity -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total unconverted OPs: 7\n",
      "\t- Total unconverted OP Types: 3\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2022-04-26 11:17:23.296604: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:765] Number of TensorRT candidate segments: 1\n",
      "2022-04-26 11:17:23.301164: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:876] Replaced segment 0 consisting of 19 nodes by TRTEngineOp_0_0.\n",
      "2022-04-26 11:17:23.317339: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 26 nodes (-12), 37 edges (-12), time = 11.443ms.\n",
      "  layout: Graph size after: 30 nodes (4), 41 edges (4), time = 2.433ms.\n",
      "  constant_folding: Graph size after: 30 nodes (0), 41 edges (0), time = 1.725ms.\n",
      "  TensorRTOptimizer: Graph size after: 12 nodes (-18), 17 edges (-24), time = 10.996ms.\n",
      "  constant_folding: Graph size after: 12 nodes (0), 17 edges (0), time = 1.189ms.\n",
      "Optimization results for grappler item: TRTEngineOp_0_0_native_segment\n",
      "  constant_folding: Graph size after: 27 nodes (0), 26 edges (0), time = 2.011ms.\n",
      "  layout: Graph size after: 27 nodes (0), 26 edges (0), time = 2.511ms.\n",
      "  constant_folding: Graph size after: 27 nodes (0), 26 edges (0), time = 1.939ms.\n",
      "  TensorRTOptimizer: Graph size after: 27 nodes (0), 26 edges (0), time = 0.245ms.\n",
      "  constant_folding: Graph size after: 27 nodes (0), 26 edges (0), time = 1.937ms.\n",
      "\n",
      "2022-04-26 11:17:23.398297: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:17:23.419371: I tensorflow/compiler/tf2tensorrt/common/utils.cc:58] Linked TensorRT version: 8.0.3\n",
      "2022-04-26 11:17:23.420044: I tensorflow/compiler/tf2tensorrt/common/utils.cc:60] Loaded TensorRT version: 8.0.3\n",
      "2022-04-26 11:17:23.925711: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger It is suggested to disable layer timing cache while using AlgorithmSelector. Please refer to the developer guide in https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#builder-layer-timing.\n",
      "2022-04-26 11:17:24.914658: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger Detected invalid timing cache, setup a local cache instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./optimized/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def optimize_model( ):\n",
    "    converter = trt.TrtGraphConverterV2(input_saved_model_dir='./saved_model',\n",
    "                                        conversion_params = tf.experimental.tensorrt.ConversionParams(\n",
    "                                            precision_mode='FP32',\n",
    "                                        )\n",
    "                                       )\n",
    "\n",
    "\n",
    "    def my_input_fn():\n",
    "        # Input for a single inference call, for a network that has two input tensors:\n",
    "        yield (np.asanyarray([train_images[0]]),)\n",
    "\n",
    "\n",
    "    converter.convert()\n",
    "    converter.build(my_input_fn)\n",
    "    converter.save('./optimized')\n",
    "\n",
    "p = multiprocessing.Process(target=optimize_model)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cea2db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU Memory before loading:  15109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:27:40.795972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:40.879579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:40.881315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:40.883759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:40.884838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:40.885818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:41.567211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:41.568945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:41.570531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:41.571726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:27:42.324756: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-26 11:27:44.365686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:44.366723: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-26 11:27:44.367122: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-26 11:27:44.368061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:44.369457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:44.370362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:44.370834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:44.371207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:44.371492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:27:44.415859: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 15 nodes (12), 20 edges (18), time = 14.613ms.\n",
      "  function_optimizer: Graph size after: 15 nodes (0), 20 edges (0), time = 3.686ms.\n",
      "Optimization results for grappler item: __inference_TRTEngineOp_0_0_native_segment_95\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.012ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU Memory after loading:  657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:27:44.736127: I tensorflow/compiler/tf2tensorrt/common/utils.cc:58] Linked TensorRT version: 8.0.3\n",
      "2022-04-26 11:27:44.736214: I tensorflow/compiler/tf2tensorrt/common/utils.cc:60] Loaded TensorRT version: 8.0.3\n",
      "2022-04-26 11:27:44.745518: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger It is suggested to disable layer timing cache while using AlgorithmSelector. Please refer to the developer guide in https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#builder-layer-timing.\n",
      "2022-04-26 11:27:44.790846: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger Detected invalid timing cache, setup a local cache instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FPS:  280.2060373878259\n",
      "GPU Memory Usage: 14452 MiB\n",
      "\n",
      "Test accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "\n",
    "num_of_iteration = 2000\n",
    "\n",
    "def get_func_from_saved_model(saved_model_dir):\n",
    "  saved_model_loaded = tf.saved_model.load(\n",
    "      saved_model_dir, tags=[tag_constants.SERVING])\n",
    "  graph_func = saved_model_loaded.signatures[\n",
    "      signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "  graph_func = convert_to_constants.convert_variables_to_constants_v2(graph_func)\n",
    "  return graph_func\n",
    "\n",
    "def evaluate_model( ):\n",
    "    mem_before = get_gpu_memory()[0]\n",
    "    print(\"Available GPU Memory before loading: \", mem_before)\n",
    "\n",
    "    model_func = get_func_from_saved_model('./optimized')\n",
    "    mem_after = get_gpu_memory()[0]\n",
    "    print(\"Available GPU Memory after loading: \", mem_after)\n",
    "\n",
    "    success = 0\n",
    "    start_time = time.time()\n",
    "    for i in range(num_of_iteration):\n",
    "        data = tf.convert_to_tensor(np.asanyarray([validation_images[i]]))\n",
    "        digit = np.argmax(model_func(data), axis=-1)[0]\n",
    "        if digit == np.argmax(validation_labels[i]):\n",
    "            success += 1\n",
    "\n",
    "    print(\"Average FPS: \", num_of_iteration / float(time.time() - start_time))\n",
    "    print(\"GPU Memory Usage: \" + str(mem_before - mem_after) + \" MiB\")\n",
    "    print('\\nTest accuracy:', float(success) / num_of_iteration)\n",
    "\n",
    "p = multiprocessing.Process(target=evaluate_model)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce445b",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Convert the model with TF-TRT to quntization single-percision and evaluate the model\n",
    "Can someone explain the suprising result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b25c47af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.01176471],\n",
      "         [0.07058824],\n",
      "         [0.07058824],\n",
      "         [0.07058824],\n",
      "         [0.49411765],\n",
      "         [0.53333336],\n",
      "         [0.6862745 ],\n",
      "         [0.10196079],\n",
      "         [0.6509804 ],\n",
      "         [1.        ],\n",
      "         [0.96862745],\n",
      "         [0.49803922],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.11764706],\n",
      "         [0.14117648],\n",
      "         [0.36862746],\n",
      "         [0.6039216 ],\n",
      "         [0.6666667 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.88235295],\n",
      "         [0.6745098 ],\n",
      "         [0.99215686],\n",
      "         [0.9490196 ],\n",
      "         [0.7647059 ],\n",
      "         [0.2509804 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.19215687],\n",
      "         [0.93333334],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.9843137 ],\n",
      "         [0.3647059 ],\n",
      "         [0.32156864],\n",
      "         [0.32156864],\n",
      "         [0.21960784],\n",
      "         [0.15294118],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.07058824],\n",
      "         [0.85882354],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.7764706 ],\n",
      "         [0.7137255 ],\n",
      "         [0.96862745],\n",
      "         [0.94509804],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.3137255 ],\n",
      "         [0.6117647 ],\n",
      "         [0.41960785],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.8039216 ],\n",
      "         [0.04313726],\n",
      "         [0.        ],\n",
      "         [0.16862746],\n",
      "         [0.6039216 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.05490196],\n",
      "         [0.00392157],\n",
      "         [0.6039216 ],\n",
      "         [0.99215686],\n",
      "         [0.3529412 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.54509807],\n",
      "         [0.99215686],\n",
      "         [0.74509805],\n",
      "         [0.00784314],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.04313726],\n",
      "         [0.74509805],\n",
      "         [0.99215686],\n",
      "         [0.27450982],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.13725491],\n",
      "         [0.94509804],\n",
      "         [0.88235295],\n",
      "         [0.627451  ],\n",
      "         [0.42352942],\n",
      "         [0.00392157],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.31764707],\n",
      "         [0.9411765 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.46666667],\n",
      "         [0.09803922],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.1764706 ],\n",
      "         [0.7294118 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.5882353 ],\n",
      "         [0.10588235],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.0627451 ],\n",
      "         [0.3647059 ],\n",
      "         [0.9882353 ],\n",
      "         [0.99215686],\n",
      "         [0.73333335],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.9764706 ],\n",
      "         [0.99215686],\n",
      "         [0.9764706 ],\n",
      "         [0.2509804 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.18039216],\n",
      "         [0.50980395],\n",
      "         [0.7176471 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.8117647 ],\n",
      "         [0.00784314],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.15294118],\n",
      "         [0.5803922 ],\n",
      "         [0.8980392 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.98039216],\n",
      "         [0.7137255 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.09411765],\n",
      "         [0.44705883],\n",
      "         [0.8666667 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.7882353 ],\n",
      "         [0.30588236],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.09019608],\n",
      "         [0.25882354],\n",
      "         [0.8352941 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.7764706 ],\n",
      "         [0.31764707],\n",
      "         [0.00784314],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.07058824],\n",
      "         [0.67058825],\n",
      "         [0.85882354],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.7647059 ],\n",
      "         [0.3137255 ],\n",
      "         [0.03529412],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.21568628],\n",
      "         [0.6745098 ],\n",
      "         [0.8862745 ],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.95686275],\n",
      "         [0.52156866],\n",
      "         [0.04313726],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.53333336],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.83137256],\n",
      "         [0.5294118 ],\n",
      "         [0.5176471 ],\n",
      "         [0.0627451 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]]], dtype=float32),)\n",
      "(array([[[[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.2       ],\n",
      "         [0.62352943],\n",
      "         [0.99215686],\n",
      "         [0.62352943],\n",
      "         [0.19607843],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.1882353 ],\n",
      "         [0.93333334],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.92941177],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.21176471],\n",
      "         [0.8901961 ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.9372549 ],\n",
      "         [0.9137255 ],\n",
      "         [0.9882353 ],\n",
      "         [0.22352941],\n",
      "         [0.02352941],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.03921569],\n",
      "         [0.23529412],\n",
      "         [0.8784314 ],\n",
      "         [0.9882353 ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.7921569 ],\n",
      "         [0.32941177],\n",
      "         [0.9882353 ],\n",
      "         [0.99215686],\n",
      "         [0.47843137],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.6392157 ],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.3764706 ],\n",
      "         [0.7411765 ],\n",
      "         [0.99215686],\n",
      "         [0.654902  ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.2       ],\n",
      "         [0.93333334],\n",
      "         [0.99215686],\n",
      "         [0.99215686],\n",
      "         [0.74509805],\n",
      "         [0.44705883],\n",
      "         [0.99215686],\n",
      "         [0.89411765],\n",
      "         [0.18431373],\n",
      "         [0.30980393],\n",
      "         [1.        ],\n",
      "         [0.65882355],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.1882353 ],\n",
      "         [0.93333334],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.7019608 ],\n",
      "         [0.04705882],\n",
      "         [0.29411766],\n",
      "         [0.4745098 ],\n",
      "         [0.08235294],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.99215686],\n",
      "         [0.9529412 ],\n",
      "         [0.19607843],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.14901961],\n",
      "         [0.64705884],\n",
      "         [0.99215686],\n",
      "         [0.9137255 ],\n",
      "         [0.8156863 ],\n",
      "         [0.32941177],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.64705884],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.02745098],\n",
      "         [0.69803923],\n",
      "         [0.9882353 ],\n",
      "         [0.9411765 ],\n",
      "         [0.2784314 ],\n",
      "         [0.07450981],\n",
      "         [0.10980392],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.7647059 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.22352941],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.24705882],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.7647059 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.7764706 ],\n",
      "         [0.99215686],\n",
      "         [0.74509805],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [1.        ],\n",
      "         [0.99215686],\n",
      "         [0.76862746],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.29803923],\n",
      "         [0.9647059 ],\n",
      "         [0.9882353 ],\n",
      "         [0.4392157 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.5803922 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.33333334],\n",
      "         [0.9882353 ],\n",
      "         [0.9019608 ],\n",
      "         [0.09803922],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.02745098],\n",
      "         [0.5294118 ],\n",
      "         [0.99215686],\n",
      "         [0.7294118 ],\n",
      "         [0.04705882],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.33333334],\n",
      "         [0.9882353 ],\n",
      "         [0.8745098 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.02745098],\n",
      "         [0.5137255 ],\n",
      "         [0.9882353 ],\n",
      "         [0.88235295],\n",
      "         [0.2784314 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.33333334],\n",
      "         [0.9882353 ],\n",
      "         [0.5686275 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.1882353 ],\n",
      "         [0.64705884],\n",
      "         [0.9882353 ],\n",
      "         [0.6784314 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.3372549 ],\n",
      "         [0.99215686],\n",
      "         [0.88235295],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.44705883],\n",
      "         [0.93333334],\n",
      "         [0.99215686],\n",
      "         [0.63529414],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.33333334],\n",
      "         [0.9882353 ],\n",
      "         [0.9764706 ],\n",
      "         [0.57254905],\n",
      "         [0.1882353 ],\n",
      "         [0.11372549],\n",
      "         [0.33333334],\n",
      "         [0.69803923],\n",
      "         [0.88235295],\n",
      "         [0.99215686],\n",
      "         [0.8745098 ],\n",
      "         [0.654902  ],\n",
      "         [0.21960784],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.33333334],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.8980392 ],\n",
      "         [0.84313726],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.76862746],\n",
      "         [0.50980395],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.10980392],\n",
      "         [0.78039217],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.9882353 ],\n",
      "         [0.9137255 ],\n",
      "         [0.5686275 ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.09803922],\n",
      "         [0.5019608 ],\n",
      "         [0.9882353 ],\n",
      "         [0.99215686],\n",
      "         [0.9882353 ],\n",
      "         [0.5529412 ],\n",
      "         [0.14509805],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]],\n",
      "\n",
      "        [[0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ],\n",
      "         [0.        ]]]], dtype=float32),)\n"
     ]
    }
   ],
   "source": [
    "def my_calibration_fn():\n",
    "    counter = 0\n",
    "    # Input for a single inference call, for a network that has two input tensors:\n",
    "    while counter < 20:\n",
    "        yield (np.asanyarray([train_images[counter]]),)\n",
    "        counter += 1\n",
    "            \n",
    "gen = my_calibration_fn()\n",
    "\n",
    "print(next(gen))\n",
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c7dca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (8, 0, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (8, 0, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:27:20.618741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:20.669749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:20.670288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:20.671702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:20.672304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:20.672796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.208540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.209664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.210399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.210926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:27:21.654175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.655161: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-26 11:27:21.655689: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-26 11:27:21.656760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.657505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.658227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.659010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.659714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.660306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:27:21.664544: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 38 nodes (28), 49 edges (39), time = 1.463ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.038ms.\n",
      "\n",
      "2022-04-26 11:27:21.721078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.721784: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-26 11:27:21.721972: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-04-26 11:27:21.723221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.723926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.724579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.725318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.726054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 11:27:21.726690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-04-26 11:27:21.753566: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:883] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/unconverted OP Report:\n",
      "\t- NoOp -> 5x\n",
      "\t- Placeholder -> 1x\n",
      "\t- Identity -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total unconverted OPs: 7\n",
      "\t- Total unconverted OP Types: 3\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2022-04-26 11:27:21.754338: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:765] Number of TensorRT candidate segments: 1\n",
      "2022-04-26 11:27:21.757813: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:876] Replaced segment 0 consisting of 19 nodes by TRTEngineOp_0_0.\n",
      "2022-04-26 11:27:21.773762: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 26 nodes (-12), 37 edges (-12), time = 12.019ms.\n",
      "  layout: Graph size after: 30 nodes (4), 41 edges (4), time = 2.502ms.\n",
      "  constant_folding: Graph size after: 30 nodes (0), 41 edges (0), time = 1.797ms.\n",
      "  TensorRTOptimizer: Graph size after: 12 nodes (-18), 17 edges (-24), time = 11.423ms.\n",
      "  constant_folding: Graph size after: 12 nodes (0), 17 edges (0), time = 1.202ms.\n",
      "Optimization results for grappler item: TRTEngineOp_0_0_native_segment\n",
      "  constant_folding: Graph size after: 27 nodes (0), 26 edges (0), time = 1.971ms.\n",
      "  layout: Graph size after: 27 nodes (0), 26 edges (0), time = 2.443ms.\n",
      "  constant_folding: Graph size after: 27 nodes (0), 26 edges (0), time = 1.969ms.\n",
      "  TensorRTOptimizer: Graph size after: 27 nodes (0), 26 edges (0), time = 0.25ms.\n",
      "  constant_folding: Graph size after: 27 nodes (0), 26 edges (0), time = 1.892ms.\n",
      "\n",
      "2022-04-26 11:27:21.853136: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 11:27:21.874160: I tensorflow/compiler/tf2tensorrt/common/utils.cc:58] Linked TensorRT version: 8.0.3\n",
      "2022-04-26 11:27:21.874287: I tensorflow/compiler/tf2tensorrt/common/utils.cc:60] Loaded TensorRT version: 8.0.3\n",
      "2022-04-26 11:27:22.382147: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger It is suggested to disable layer timing cache while using AlgorithmSelector. Please refer to the developer guide in https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#builder-layer-timing.\n",
      "2022-04-26 11:27:24.520298: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8300\n",
      "2022-04-26 11:27:27.548544: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger Detected invalid timing cache, setup a local cache instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./optimized/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def optimize_model( ):\n",
    "    converter = trt.TrtGraphConverterV2(input_saved_model_dir='./saved_model',\n",
    "                                        conversion_params = tf.experimental.tensorrt.ConversionParams(\n",
    "                                            precision_mode='INT8',\n",
    "                                        )\n",
    "                                       )\n",
    "\n",
    "    def my_calibration_fn():\n",
    "        counter = 0\n",
    "        # Input for a single inference call, for a network that has two input tensors:\n",
    "        while counter < 20:\n",
    "            yield (np.asanyarray([train_images[counter]]),)\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "    def my_input_fn():\n",
    "        # Input for a single inference call, for a network that has two input tensors:\n",
    "        yield (np.asanyarray([train_images[0]]),)\n",
    "\n",
    "\n",
    "    converter.convert(my_calibration_fn)\n",
    "    converter.build(my_input_fn)\n",
    "    converter.save('./optimized')\n",
    "\n",
    "p = multiprocessing.Process(target=optimize_model)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2378ee",
   "metadata": {},
   "source": [
    "https://docs.nvidia.com/deeplearning/tensorrt/best-practices/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
