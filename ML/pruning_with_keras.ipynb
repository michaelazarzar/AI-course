{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# Pruining - how to compress neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pruning.png\" height=\"50%\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bjmi3qZeu_xk"
   },
   "source": [
    "## Background\n",
    "Modern state-of-the-art neural network architectures are HUGE. For instance, you have probably heard about GPT-3, OpenAI’s newest revolutionary NLP model, capable of writing poetry and interactive storytelling.\n",
    "\n",
    "Well, GPT-3 has around 175 billion parameters.\n",
    "\n",
    "According to GPT-3 original paper, it required 3.14E+23 flops of training time, and the computing cost itself is in the millions of dollars.\n",
    "\n",
    "Beside that importent note more issues arise with model size when trying to run inference on edge computer, since its low on resources some of the models would not fit in the edge device memory and some wont even be able to optimize on the edge device.\n",
    "\n",
    "<img src=\"images/gpt3.png\">\n",
    "\n",
    "\n",
    "To optimize these costs by compressing the models, three main methods have emerged:\n",
    "* weight pruning\n",
    "* quantization\n",
    "* knowledge distillation\n",
    "\n",
    "## Pruning\n",
    "We can think of pruning as the **\"optimal brain-damage\"**, because thats essentialy what it is, all of the pruning methods trying to shed the least significant weights from the model without degregation in its performance.\n",
    "\n",
    "This subject is under heavy research and most of it is premature, I'll go over one trending pruning solution backed up with an article called \"The winning lottory ticket hypotesis\".\n",
    "\n",
    "> A randomly-initialized, dense neural network contains a subnetwork that is initialized such that — when trained in isolation — it can match the test accuracy of the original network after training for at most the same number of iterations.\n",
    "\n",
    "That means that if we train a big model initialized with random weights, see what weights are getting toward zero and removing them from the model, we can potentialy win a lottory ticket in a form of a subnetwork that correspond to the article hypotesis.\n",
    "\n",
    "The authors suggest the following algorithm to do so:\n",
    "* Randomly initialize the network and store the initial weights for later reference.\n",
    "* Train the network for a given number of steps.\n",
    "* Remove a percentage of the weights with the lowest magnitude.\n",
    "* Restore the remaining weights to the value that was given during the first initialization.\n",
    "* Go to Step 2. and iterate the pruning.\n",
    "\n",
    "## Quantization\n",
    "Quantization is using smaller data types to express the different weights in the model, thus instead of using FP32 multiplication we can use FP16, INT8 and tensor cores.\n",
    "\n",
    "This can be acheived using dynamic range remapping, the algorithm learns the range in which the weights multiplications values are changing, and remap these values to a smaller data type.\n",
    "\n",
    "## Knowlege Distilation\n",
    "Knowlege distilation is an approach developed by  Geoffrey Hinton, Oriol Vinyals, and Jeff Dean in their paper Distilling the Knowledge in a Neural Network.\n",
    "\n",
    "The method says that we can train a super network with lots of parameters, it will serve as the teacher, which in turn teach different smaller architecture and try to acheive high accuracy while using smaller more production-ready networks.\n",
    "\n",
    "\n",
    "#### In this article we will go over pruning technichue with TensorFlow framework, we will start with a Dense network and create a Sparse subnetwork out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEAZYXvZU_XG"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:07:03.659113Z",
     "iopub.status.busy": "2021-05-18T11:07:03.658388Z",
     "iopub.status.idle": "2021-05-18T11:07:05.336493Z",
     "shell.execute_reply": "2021-05-18T11:07:05.335874Z"
    },
    "id": "zN4yVFK5-0Bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/include/python3.8/UNKNOWN\n",
      "sysconfig: /usr/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/lib/python3.8/dist-packages\n",
      "  sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/lib/python3.8/dist-packages\n",
      "  sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/include/python3.8/dm-tree\n",
      "  sysconfig: /usr/include/python3.8/dm-tree\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/bin\n",
      "  sysconfig: /usr/bin\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local\n",
      "  sysconfig: /usr\u001b[0m\n",
      "\u001b[33m  WARNING: Additional context:\n",
      "  user = False\n",
      "  home = None\n",
      "  root = None\n",
      "  prefix = None\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/lib/python3.8/dist-packages\n",
      "  sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/lib/python3.8/dist-packages\n",
      "  sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/include/python3.8/tensorflow-model-optimization\n",
      "  sysconfig: /usr/include/python3.8/tensorflow-model-optimization\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local/bin\n",
      "  sysconfig: /usr/bin\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "  distutils: /usr/local\n",
      "  sysconfig: /usr\u001b[0m\n",
      "\u001b[33m  WARNING: Additional context:\n",
      "  user = False\n",
      "  home = None\n",
      "  root = None\n",
      "  prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/lib/python3.8/dist-packages\n",
      "sysconfig: /usr/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/include/python3.8/UNKNOWN\n",
      "sysconfig: /usr/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/bin\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:07:05.342146Z",
     "iopub.status.busy": "2021-05-18T11:07:05.341468Z",
     "iopub.status.idle": "2021-05-18T11:07:13.034519Z",
     "shell.execute_reply": "2021-05-18T11:07:13.033904Z"
    },
    "id": "yJwIonXEVJo6"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psViY5PRDurp"
   },
   "source": [
    "## Train a model for MNIST without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:07:13.043472Z",
     "iopub.status.busy": "2021-05-18T11:07:13.042688Z",
     "iopub.status.idle": "2021-05-18T11:07:51.348065Z",
     "shell.execute_reply": "2021-05-18T11:07:51.348525Z"
    },
    "id": "pbY-KGMPvbW9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2920 - accuracy: 0.9182 - val_loss: 0.1170 - val_accuracy: 0.9700\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1169 - accuracy: 0.9676 - val_loss: 0.0803 - val_accuracy: 0.9770\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9751 - val_loss: 0.0808 - val_accuracy: 0.9775\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0715 - accuracy: 0.9784 - val_loss: 0.0647 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff30c71c940>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1qKfXNqo9hk"
   },
   "source": [
    "Evaluate baseline test accuracy and save the model for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:07:51.354169Z",
     "iopub.status.busy": "2021-05-18T11:07:51.353489Z",
     "iopub.status.idle": "2021-05-18T11:07:51.998066Z",
     "shell.execute_reply": "2021-05-18T11:07:51.997456Z"
    },
    "id": "RyIKnbVZafIH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Baseline test accuracy: 0.9785000085830688\n",
      "Saved baseline model to: /tmp/tmpnmotx8yj.h5\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8747K9OE72P"
   },
   "source": [
    "## Fine-tune pre-trained model with pruning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F19k7ExXF_h2"
   },
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsZROpNYMWQ0"
   },
   "source": [
    "You will apply pruning to the whole model and see this in the model summary.\n",
    "\n",
    "In this example, you start the model with 50% sparsity (50% zeros in weights)\n",
    "and end with 80% sparsity.\n",
    "\n",
    "https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:07:52.005363Z",
     "iopub.status.busy": "2021-05-18T11:07:52.004694Z",
     "iopub.status.idle": "2021-05-18T11:07:52.679035Z",
     "shell.execute_reply": "2021-05-18T11:07:52.678492Z"
    },
    "id": "oq6blGjgFDCW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py:2191: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDr2ijwpGCI-"
   },
   "source": [
    "### Train and evaluate the model against baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUBEn94hXYB1"
   },
   "source": [
    "Fine tune with pruning for two epochs.\n",
    "\n",
    "`tfmot.sparsity.keras.UpdatePruningStep` is required during training, and `tfmot.sparsity.keras.PruningSummaries` provides logs for tracking progress and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:07:52.684796Z",
     "iopub.status.busy": "2021-05-18T11:07:52.684101Z",
     "iopub.status.idle": "2021-05-18T11:08:01.771571Z",
     "shell.execute_reply": "2021-05-18T11:08:01.771052Z"
    },
    "id": "_PHDGJryE31X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "  3/422 [..............................] - ETA: 1:04 - loss: 0.1008 - accuracy: 0.9714WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0052s vs `on_train_batch_begin` time: 0.0326s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_train_batch_end` time: 0.0184s). Check your callbacks.\n",
      "422/422 [==============================] - 5s 8ms/step - loss: 0.0868 - accuracy: 0.9765 - val_loss: 0.0912 - val_accuracy: 0.9775\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.1005 - accuracy: 0.9735 - val_loss: 0.0860 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff2e9249430>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "  \n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-byC2lYlMkfN"
   },
   "source": [
    "For this example, there is minimal loss in test accuracy after pruning, compared to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:08:01.777102Z",
     "iopub.status.busy": "2021-05-18T11:08:01.776441Z",
     "iopub.status.idle": "2021-05-18T11:08:02.442054Z",
     "shell.execute_reply": "2021-05-18T11:08:02.441528Z"
    },
    "id": "6bMFTKSSHyyZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9785000085830688\n",
      "Pruned test accuracy: 0.9721999764442444\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQFiZsqqc0vS"
   },
   "source": [
    "The logs show the progression of sparsity on a per-layer basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LdLm4hVYc1wx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7c2f2ea75b671ab9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7c2f2ea75b671ab9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8890;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir={logdir} --port 8890 --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IepmUPSITn6"
   },
   "source": [
    "## Create 3x smaller models from pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FgNP4rbOLH8"
   },
   "source": [
    "Both `tfmot.sparsity.keras.strip_pruning` and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression\n",
    "benefits of pruning.\n",
    "\n",
    "*   `strip_pruning` is necessary since it removes every tf.Variable that pruning only needs during training, which would otherwise add to model size during inference\n",
    "*   Applying a standard compression algorithm is necessary since the serialized weight matrices are the same size as they were before pruning. However, pruning makes most of the weights zeros, which is\n",
    "added redundancy that algorithms can utilize to further compress the model.\n",
    "\n",
    "First, create a compressible model for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:08:02.449539Z",
     "iopub.status.busy": "2021-05-18T11:08:02.448847Z",
     "iopub.status.idle": "2021-05-18T11:08:02.482882Z",
     "shell.execute_reply": "2021-05-18T11:08:02.482244Z"
    },
    "id": "w7fztWsAOHTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved pruned Keras model to: /tmp/tmpyfebzim1.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4lv-lRKuMY4"
   },
   "source": [
    "Define a helper function to actually compress the models via gzip and measure the zipped size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:08:03.288076Z",
     "iopub.status.busy": "2021-05-18T11:08:03.287407Z",
     "iopub.status.idle": "2021-05-18T11:08:03.289968Z",
     "shell.execute_reply": "2021-05-18T11:08:03.289406Z"
    },
    "id": "-E7DXEgUrCDZ"
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caxUoJ_BunqU"
   },
   "source": [
    "Compare and see that the models are 3x smaller from pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T11:08:03.295060Z",
     "iopub.status.busy": "2021-05-18T11:08:03.294373Z",
     "iopub.status.idle": "2021-05-18T11:08:03.314602Z",
     "shell.execute_reply": "2021-05-18T11:08:03.314039Z"
    },
    "id": "HzSXC_nxuqJX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78169.00 bytes\n",
      "Size of gzipped pruned Keras model: 25795.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pruning_with_keras.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
